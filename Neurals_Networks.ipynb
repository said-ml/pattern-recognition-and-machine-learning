{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fe20116a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "from ipynb.fs.full.DS_Linear_Algebra import dot\n",
    "import math\n",
    "from typing import List\n",
    "\n",
    "def sigmoid(t):\n",
    "    return 1/(1+math.exp(-t))\n",
    "\n",
    "def neuron_output(weights, inputs):\n",
    "    return dot(weights, inputs)\n",
    "\n",
    "Vector=List[float]\n",
    "Matrix=List[Vector]\n",
    "\n",
    "def feed_forward(neural_network: List[List[Vector]],\n",
    "                 input_vector: Vector) -> List[Vector]:\n",
    "    \"\"\"\n",
    "    Feeds the input vector through the neural network.\n",
    "    Returns the outputs of all layers (not just the last one).\n",
    "    \"\"\"\n",
    "    outputs: List[Vector] = []\n",
    "\n",
    "    for layer in neural_network:\n",
    "        input_with_bias = input_vector +[1]             # Add a constant.\n",
    "        output = [neuron_output(neuron, input_with_bias)  # Compute the output\n",
    "                  for neuron in layer]                    # for each neuron.\n",
    "        outputs.append(output)                            # Add to results.\n",
    "\n",
    "        # Then the input to the next layer is the output of this one\n",
    "        input_vector = output\n",
    "\n",
    "    return outputs\n",
    "xor_network = [# hidden layer\n",
    "               [[20., 20, -30],      # 'and' neuron\n",
    "                [20., 20, -10]],     # 'or'  neuron\n",
    "               # output layer\n",
    "               [[-60., 60, -30]]]    # '2nd input but not 1st input' neur\n",
    "\n",
    "\n",
    "\n",
    "# feed_forward returns the outputs of all layers, \n",
    "# so the [-1]  gets the final outputs, and [0] gets the value of resulting\n",
    "# feed_forward(xor_network, [0, 0]) ####---------###### 'errors'='ignore'\n",
    "\n",
    "def sqerror_gradients(network:Matrix, input_Vector:Vector, target_vector:Vector)->Matrix:\n",
    "    ''' Given a neural_network, an input vector, and an target vector , make a \n",
    "        prediction and compute the gradient of the squred error loss  \n",
    "        with respect to the neuron weights '''\n",
    "    # forward pass\n",
    "    hidden_outputs, outputs=feed_forward(networ, input_vector)\n",
    "    \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66008b98",
   "metadata": {},
   "source": [
    "# The Perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bc7fd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.097064</td>\n",
       "      <td>-2.073335</td>\n",
       "      <td>1.269934</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.568466</td>\n",
       "      <td>3.283515</td>\n",
       "      <td>2.652874</td>\n",
       "      <td>2.532475</td>\n",
       "      <td>2.217515</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.359293</td>\n",
       "      <td>2.303601</td>\n",
       "      <td>2.001237</td>\n",
       "      <td>1.307686</td>\n",
       "      <td>2.616665</td>\n",
       "      <td>2.109526</td>\n",
       "      <td>2.296076</td>\n",
       "      <td>2.750622</td>\n",
       "      <td>1.937015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.829821</td>\n",
       "      <td>-0.353632</td>\n",
       "      <td>1.685955</td>\n",
       "      <td>1.908708</td>\n",
       "      <td>-0.826962</td>\n",
       "      <td>-0.487072</td>\n",
       "      <td>-0.023846</td>\n",
       "      <td>0.548144</td>\n",
       "      <td>0.001392</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.369203</td>\n",
       "      <td>1.535126</td>\n",
       "      <td>1.890489</td>\n",
       "      <td>-0.375612</td>\n",
       "      <td>-0.430444</td>\n",
       "      <td>-0.146749</td>\n",
       "      <td>1.087084</td>\n",
       "      <td>-0.243890</td>\n",
       "      <td>0.281190</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.579888</td>\n",
       "      <td>0.456187</td>\n",
       "      <td>1.566503</td>\n",
       "      <td>1.558884</td>\n",
       "      <td>0.942210</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>1.363478</td>\n",
       "      <td>2.037231</td>\n",
       "      <td>0.939685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023974</td>\n",
       "      <td>1.347475</td>\n",
       "      <td>1.456285</td>\n",
       "      <td>0.527407</td>\n",
       "      <td>1.082932</td>\n",
       "      <td>0.854974</td>\n",
       "      <td>1.955000</td>\n",
       "      <td>1.152255</td>\n",
       "      <td>0.201391</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-0.768909</td>\n",
       "      <td>0.253732</td>\n",
       "      <td>-0.592687</td>\n",
       "      <td>-0.764464</td>\n",
       "      <td>3.283553</td>\n",
       "      <td>3.402909</td>\n",
       "      <td>1.915897</td>\n",
       "      <td>1.451707</td>\n",
       "      <td>2.867383</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133984</td>\n",
       "      <td>-0.249939</td>\n",
       "      <td>-0.550021</td>\n",
       "      <td>3.394275</td>\n",
       "      <td>3.893397</td>\n",
       "      <td>1.989588</td>\n",
       "      <td>2.175786</td>\n",
       "      <td>6.046041</td>\n",
       "      <td>4.935010</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.750297</td>\n",
       "      <td>-1.151816</td>\n",
       "      <td>1.776573</td>\n",
       "      <td>1.826229</td>\n",
       "      <td>0.280372</td>\n",
       "      <td>0.539340</td>\n",
       "      <td>1.371011</td>\n",
       "      <td>1.428493</td>\n",
       "      <td>-0.009560</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.466770</td>\n",
       "      <td>1.338539</td>\n",
       "      <td>1.220724</td>\n",
       "      <td>0.220556</td>\n",
       "      <td>-0.313395</td>\n",
       "      <td>0.613179</td>\n",
       "      <td>0.729259</td>\n",
       "      <td>-0.868353</td>\n",
       "      <td>-0.397100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  mean radius  mean texture  mean perimeter  mean area  \\\n",
       "0           0     1.097064     -2.073335        1.269934   0.984375   \n",
       "1           1     1.829821     -0.353632        1.685955   1.908708   \n",
       "2           2     1.579888      0.456187        1.566503   1.558884   \n",
       "3           3    -0.768909      0.253732       -0.592687  -0.764464   \n",
       "4           4     1.750297     -1.151816        1.776573   1.826229   \n",
       "\n",
       "   mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "0         1.568466          3.283515        2.652874             2.532475   \n",
       "1        -0.826962         -0.487072       -0.023846             0.548144   \n",
       "2         0.942210          1.052926        1.363478             2.037231   \n",
       "3         3.283553          3.402909        1.915897             1.451707   \n",
       "4         0.280372          0.539340        1.371011             1.428493   \n",
       "\n",
       "   mean symmetry  ...  worst texture  worst perimeter  worst area  \\\n",
       "0       2.217515  ...      -1.359293         2.303601    2.001237   \n",
       "1       0.001392  ...      -0.369203         1.535126    1.890489   \n",
       "2       0.939685  ...      -0.023974         1.347475    1.456285   \n",
       "3       2.867383  ...       0.133984        -0.249939   -0.550021   \n",
       "4      -0.009560  ...      -1.466770         1.338539    1.220724   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0          1.307686           2.616665         2.109526              2.296076   \n",
       "1         -0.375612          -0.430444        -0.146749              1.087084   \n",
       "2          0.527407           1.082932         0.854974              1.955000   \n",
       "3          3.394275           3.893397         1.989588              2.175786   \n",
       "4          0.220556          -0.313395         0.613179              0.729259   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  target  \n",
       "0        2.750622                 1.937015       0  \n",
       "1       -0.243890                 0.281190       0  \n",
       "2        1.152255                 0.201391       0  \n",
       "3        6.046041                 4.935010       0  \n",
       "4       -0.868353                -0.397100       0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading in the data\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "# Visualization\n",
    "import matplotlib as mpl   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Building the network \n",
    "import numpy as np\n",
    "\n",
    "# Progress Bar\n",
    "\n",
    "import tqdm as tqdm\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter('ignore')\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\") #supresses warningsmport matplotlib.pyplot as plt\n",
    "\n",
    "# Loading The Data:\n",
    "full_df = pd.read_csv('https://raw.githubusercontent.com/karthikb19/data/master/breastcancer.csv') #preprocessed data\n",
    "full_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1d4285f",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 35 (920581979.py, line 38)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [3]\u001b[0;36m\u001b[0m\n\u001b[0;31m    def plot_MSE(self, MSE:callable,n_iterations:np.float_ )->np.float:\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 35\n"
     ]
    }
   ],
   "source": [
    "class Perceptron:\n",
    "    \n",
    "    def ___init__(self, inputs:np.array(()), outputs:np.array(()), act_fun:callable='sigmoid')->None:\n",
    "        self.inputs=inputs\n",
    "        self.outputs=outputs\n",
    "        self.act_fun=act_fun\n",
    "        n_rows, n_columns=inputs.shape, outputs.sahpe\n",
    "        weights=np.ones(n_rows, n_columns)\n",
    "        \n",
    "    def func_gradient(self, f:callable, z:np.float_)->np.float_:\n",
    "        epsilon=0.00000001\n",
    "        return (f(z+epsilon)-f(z))/epsilon\n",
    "\n",
    "    def sigmoid(self, t:np.float_)->np.float_:\n",
    "        return 1/(1+np.exp(-t))\n",
    "    \n",
    "    def derive_sigmoid(self, t:np.float_)->np.float_:\n",
    "        s=self.sigmoid(t)\n",
    "        return s*(1-s)\n",
    "    \n",
    "    def feed_forward(self)->np.float():\n",
    "        z=np.dot(self.inputs, self.weights)\n",
    "        y_estimator=self.act_fun(z)\n",
    "        return y_estimator\n",
    "    \n",
    "    def back_propa(self)->np.float_:\n",
    "        lear_rate=0.5\n",
    "        y_hat=self.feed_forward(x)\n",
    "        z=np.dot(self.weights, self.inputs)\n",
    "        return lear_rate*(y_hat-output)*self.func_gradient(self.act_fun(z))*inputs\n",
    "    \n",
    "    def MSE(self, y_estimaor:np.arra(()), y:np.array(()))->np.float_:\n",
    "        N=len(y)\n",
    "        return [(yi_estimator-yi) for yi_estimator, yi in zip(y_estimator, y)].sum()\n",
    "    def fit(self, inputs:np.array(()), outputs:np.array(()))->None:\n",
    "        \n",
    "    \n",
    "    def plot_MSE(self, MSE:callable,n_iterations:np.float_ )->np.float:\n",
    "        import matplotlib.pyplot as plt\n",
    "        MSE=[]\n",
    "        for i in range(n_iterations):\n",
    "            y_estimator=self.feed_forward()\n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3997e5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.05129329438755058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>-0.320167</td>\n",
       "      <td>0.346815</td>\n",
       "      <td>-0.348429</td>\n",
       "      <td>-0.385345</td>\n",
       "      <td>1.219756</td>\n",
       "      <td>-0.539188</td>\n",
       "      <td>-0.721149</td>\n",
       "      <td>-0.579569</td>\n",
       "      <td>2.659279</td>\n",
       "      <td>-0.273259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.255213</td>\n",
       "      <td>-0.489715</td>\n",
       "      <td>-0.463884</td>\n",
       "      <td>-0.116980</td>\n",
       "      <td>-0.914547</td>\n",
       "      <td>-0.916656</td>\n",
       "      <td>-0.786396</td>\n",
       "      <td>0.477640</td>\n",
       "      <td>-1.085918</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>-1.678039</td>\n",
       "      <td>0.328198</td>\n",
       "      <td>-1.594021</td>\n",
       "      <td>-1.282659</td>\n",
       "      <td>-0.164412</td>\n",
       "      <td>0.495752</td>\n",
       "      <td>0.543639</td>\n",
       "      <td>-0.702606</td>\n",
       "      <td>1.498279</td>\n",
       "      <td>2.808612</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658341</td>\n",
       "      <td>-1.464904</td>\n",
       "      <td>-1.108862</td>\n",
       "      <td>1.342755</td>\n",
       "      <td>1.124281</td>\n",
       "      <td>1.275717</td>\n",
       "      <td>-0.545359</td>\n",
       "      <td>0.681481</td>\n",
       "      <td>3.582864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>-1.248609</td>\n",
       "      <td>-0.919110</td>\n",
       "      <td>-1.161112</td>\n",
       "      <td>-1.008772</td>\n",
       "      <td>0.771413</td>\n",
       "      <td>1.052926</td>\n",
       "      <td>4.042709</td>\n",
       "      <td>0.764814</td>\n",
       "      <td>2.688487</td>\n",
       "      <td>4.275833</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.007551</td>\n",
       "      <td>-1.078879</td>\n",
       "      <td>-0.879102</td>\n",
       "      <td>-0.138898</td>\n",
       "      <td>0.145898</td>\n",
       "      <td>2.635815</td>\n",
       "      <td>0.647036</td>\n",
       "      <td>0.335276</td>\n",
       "      <td>2.324925</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.845593</td>\n",
       "      <td>-1.445027</td>\n",
       "      <td>-0.869073</td>\n",
       "      <td>-0.776409</td>\n",
       "      <td>0.083955</td>\n",
       "      <td>-1.008427</td>\n",
       "      <td>-0.866033</td>\n",
       "      <td>-0.801139</td>\n",
       "      <td>0.067109</td>\n",
       "      <td>-0.247742</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.527023</td>\n",
       "      <td>-0.923695</td>\n",
       "      <td>-0.773100</td>\n",
       "      <td>0.075898</td>\n",
       "      <td>-1.046800</td>\n",
       "      <td>-0.964439</td>\n",
       "      <td>-0.906686</td>\n",
       "      <td>-0.067552</td>\n",
       "      <td>-0.899167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>-0.277565</td>\n",
       "      <td>-0.919110</td>\n",
       "      <td>-0.274287</td>\n",
       "      <td>-0.329885</td>\n",
       "      <td>-0.179357</td>\n",
       "      <td>-0.366919</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>-0.363415</td>\n",
       "      <td>0.037902</td>\n",
       "      <td>-0.103146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.843079</td>\n",
       "      <td>-0.285682</td>\n",
       "      <td>-0.357354</td>\n",
       "      <td>0.676449</td>\n",
       "      <td>-0.182350</td>\n",
       "      <td>0.137744</td>\n",
       "      <td>-0.264733</td>\n",
       "      <td>1.534051</td>\n",
       "      <td>0.132121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "150    -0.320167      0.346815       -0.348429  -0.385345         1.219756   \n",
       "151    -1.678039      0.328198       -1.594021  -1.282659        -0.164412   \n",
       "152    -1.248609     -0.919110       -1.161112  -1.008772         0.771413   \n",
       "153    -0.845593     -1.445027       -0.869073  -0.776409         0.083955   \n",
       "154    -0.277565     -0.919110       -0.274287  -0.329885        -0.179357   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "150         -0.539188       -0.721149            -0.579569       2.659279   \n",
       "151          0.495752        0.543639            -0.702606       1.498279   \n",
       "152          1.052926        4.042709             0.764814       2.688487   \n",
       "153         -1.008427       -0.866033            -0.801139       0.067109   \n",
       "154         -0.366919        0.051861            -0.363415       0.037902   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "150               -0.273259  ...      -0.255213        -0.489715   -0.463884   \n",
       "151                2.808612  ...       0.658341        -1.464904   -1.108862   \n",
       "152                4.275833  ...      -1.007551        -1.078879   -0.879102   \n",
       "153               -0.247742  ...      -1.527023        -0.923695   -0.773100   \n",
       "154               -0.103146  ...      -0.843079        -0.285682   -0.357354   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "150         -0.116980          -0.914547        -0.916656   \n",
       "151          1.342755           1.124281         1.275717   \n",
       "152         -0.138898           0.145898         2.635815   \n",
       "153          0.075898          -1.046800        -0.964439   \n",
       "154          0.676449          -0.182350         0.137744   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  target  \n",
       "150             -0.786396        0.477640                -1.085918       1  \n",
       "151             -0.545359        0.681481                 3.582864       1  \n",
       "152              0.647036        0.335276                 2.324925       1  \n",
       "153             -0.906686       -0.067552                -0.899167       1  \n",
       "154             -0.264733        1.534051                 0.132121       1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "def binary_crossentropy(y, yhat):\n",
    "  #code is derived from the piecewise function\n",
    "  if y == 0:\n",
    "    return -np.log(1.0-yhat)\n",
    "\n",
    "  if y == 1:\n",
    "    return -np.log(yhat)\n",
    "\n",
    "y = 0 \n",
    "yhat = 0.05 \n",
    "\n",
    "print(f'Loss: {binary_crossentropy(y, yhat)}')\n",
    "# Loading in the data\n",
    "import sklearn\n",
    "from sklearn.datasets import load_breast_cancer \n",
    "# Visualization\n",
    "import matplotlib as mpl   \n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Building the network \n",
    "import numpy as np\n",
    "\n",
    "# Progress Bar\n",
    "import tqdm as tqdm\n",
    "\n",
    "#import warnings\n",
    "#warnings.filterwarnings(\"ignore\") #supresses warnings\n",
    "\n",
    "\n",
    "full_df = pd.read_csv('https://raw.githubusercontent.com/karthikb19/data/master/breastcancer.csv') #preprocessed data\n",
    "full_df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "start_index = 150 #@param {type:\"slider\", min:0, max:564, step:1}\n",
    "full_df[start_index:start_index+5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec111e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = full_df.drop('target', inplace=False, axis=1) #remove 'target' column from input features\n",
    "y_train = full_df['target'] #stores target (1 or 0) in a separate array\n",
    "\n",
    "#since we shuffled, the index numbers were messed up, this resets them\n",
    "X_train = X_train.reset_index(drop=True) \n",
    "y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "#convert to numpy arrays with float values\n",
    "X_train = np.array(X_train, dtype=float)\n",
    "y_train = np.array(y_train, dtype=float)\n",
    "\n",
    "#reshape y_train to make matrix multiplication possible\n",
    "y_train = np.array(y_train).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1adae416",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, x, y):\n",
    "\n",
    "        self.input = np.array(x, dtype=float) \n",
    "        self.label = np.array(y, dtype=float)\n",
    "        self.weights = np.random.rand(x.shape[1], y.shape[1]) #randomly initialize the weights\n",
    "        self.z = self.input@self.weights #dot product of the vectors\n",
    "        self.yhat = self.sigmoid(self.z) #apply activation function\n",
    "\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        return 1.0/(1.0+np.exp(-x))\n",
    "\n",
    "    def sigmoid_deriv(self, x):\n",
    "        s = sigmoid(x)\n",
    "        return s(1-s)\n",
    "\n",
    "    def forward_prop(self):\n",
    "        self.yhat = self.sigmoid(self.input @ self.weights) #@ symbol represents matrix multiplication (also works for vectors)\n",
    "        return self.yhat\n",
    "\n",
    "    def back_prop(self):\n",
    "        gradient = self.input.T @ (-2.0*(self.label - self.yhat)*self.sigmoid(self.yhat))  #self.input is the x value\n",
    "\n",
    "        self.weights -= gradient #process of finding the minimum loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5180b81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean Squared Error: [0.01506179]\n"
     ]
    }
   ],
   "source": [
    "simple_nn = Perceptron(X_train, y_train)\n",
    "training_iterations = 1000\n",
    "\n",
    "history = [] #we will store how the mean squared error changes after each iteration in this array\n",
    "\n",
    "def mse(yhat, y):\n",
    "    sum = 0.0\n",
    "    for pred, label in zip(yhat, y):\n",
    "        sum += (pred-label)**2\n",
    "    return sum/len(yhat)\n",
    "\n",
    "for i in range(training_iterations):\n",
    "    simple_nn.forward_prop()\n",
    "    simple_nn.back_prop()\n",
    "    yhat = simple_nn.forward_prop()\n",
    "    history.append(mse(yhat, simple_nn.label))\n",
    "\n",
    "    \n",
    "    \n",
    "yhat = simple_nn.forward_prop()\n",
    "\n",
    "\n",
    "print(f'Final Mean Squared Error: {mse(yhat, simple_nn.label)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "391b8c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Training Iteration')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history)\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.xlabel('Training Iteration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ef5f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 import libraries\n",
    "\n",
    "# we import numpy to buiold the perceptron \n",
    "import numpy as np\n",
    "# pandas is high library for manipulation of data\n",
    "import pandas as pd\n",
    "# matplotlib for visualisation of a data and loss_fuction etc..\n",
    "import matplotlib.pyplot as plt\n",
    "# sklearn is a famous libraries for machine learning\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# we use warning to display the message warning messages()\n",
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter('ignore')  \n",
    "# to make python code a little bit faster\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c37d1ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get some informations about data\n",
    "#df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90cbc412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((143, 31), (143, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 Data Preparation:\n",
    "df=pd.read_csv('https://raw.githubusercontent.com/karthikb19/data/master/breastcancer.csv')\n",
    "df[\"target\"]\n",
    "# the target value is in the last columns of DataFrame \n",
    "y=df['target']\n",
    "# so we must drop out\n",
    "df.drop(columns=['target'], inplace=True)\n",
    "X=df\n",
    "y.head()\n",
    "\n",
    "# Convert df to numpy.array(())\n",
    "#X=X.to_numpy()\n",
    "x_train, y_train, x_test, y_test=train_test_split(X, y, random_state=42)\n",
    "# convert data to numpy.array(())\n",
    "x_train, x_test, y_train, y_test=x_train.to_numpy(), y_train.to_numpy(), x_test.to_numpy(), y_test.to_numpy()\n",
    "# reshape the data for manipulation of the matrix calculs\n",
    "y_train, y_test=y_train.reshape(-1,1), y_test.reshape(-1,1)\n",
    "x_train.T.shape, y_train.shape\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a526d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3-Build The Perceptron from Scratch\n",
    "N, P=x_train.shape\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, x, y, weights=None, learning_rate=0.01, n_iterations=100):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        self.weights = np.ones((x.shape[1], y.shape[1]))#np.random.rand(x.shape[1], y.shape[1]) #randomly initialize the weights\n",
    "        self.learning_rate=0.5 # the parametrer of gradien descent weights=weights-learnin_rate*gradient\n",
    "        self.n_iterations=n_iterations\n",
    "        \n",
    "    def sigmoid(self, t):           # for this perceptron we take sigmoid as activation function\n",
    "        return 1/(1+np.exp(-t))\n",
    "    \n",
    "    def derive_sigmoid(self, t):    # d'(sigmoid)=sigmoid*(1-sigmoid)\n",
    "        s=self.sigmoid(t)\n",
    "        return s*(1-s)\n",
    "        \n",
    "    def feed_forward(self):\n",
    "        z=self.x@self.weights         # the usual product scalar of input and weights: a@b  <==> np.dot(a,b)\n",
    "        y_estimator=self.sigmoid(z)\n",
    "        return y_estimator\n",
    "    \n",
    "    def backpropagation(self):\n",
    "        for x, y in zip(self.x, self.y):\n",
    "          for i in range(self.n_iterations):\n",
    "             y_estimator=self.feed_forward()\n",
    "             gradient = self.x.T@ (-2.0*(self.y - y_estimator)*self.sigmoid(y_estimator)) \n",
    "             self.weights=self.weights-self.learning_rate*gradient\n",
    "    \n",
    "    def _prediction(self, x):\n",
    "        y=self.sigmoid(np.dot(x, self.weights))\n",
    "        return y\n",
    "    \n",
    "    def prediction(self, X):\n",
    "        return np.array(([self._prediction(x) for x in X]))\n",
    "    \n",
    "perceptron=Perceptron(x_train, y_train)\n",
    "x_train=x_train\n",
    "perceptron.backpropagation()\n",
    "y_pred=perceptron.prediction(x_test)\n",
    "y_pred\n",
    "#y_pred[0].shape\n",
    "#print(accuracy_score(y_pred, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb76fa74",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "MSE() missing 2 required positional arguments: 'y' and 'yhat'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprediction\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function(X\u001b[38;5;241m.\u001b[39mdot(W))\n\u001b[0;32m---> 32\u001b[0m perceptron\u001b[38;5;241m=\u001b[39m\u001b[43mPerceptron\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m perceptron\u001b[38;5;241m.\u001b[39mfit(x_train, y_train)\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mPerceptron.__init__\u001b[0;34m(self, n_iterations, loss, activation_function, learning_rate)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m500\u001b[39m,loss\u001b[38;5;241m=\u001b[39mMSE, activation_function\u001b[38;5;241m=\u001b[39msigmoid, learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m):\n\u001b[1;32m     13\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iterations\u001b[38;5;241m=\u001b[39mn_iterations\n\u001b[0;32m---> 14\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m=\u001b[39m\u001b[43mloss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_function\u001b[38;5;241m=\u001b[39mactivation_function()\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate\u001b[38;5;241m=\u001b[39mlearning_rate\n",
      "\u001b[0;31mTypeError\u001b[0m: MSE() missing 2 required positional arguments: 'y' and 'yhat'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from  sklearn.metrics import mean_squared_error\n",
    "\n",
    "def sigmoid( t):           # for this perceptron we take sigmoid as activation function\n",
    "        return 1/(1+np.exp(-t))\n",
    "\n",
    "def MSE(y,yhat):\n",
    "    return  (np.linalg.norm(y-yhat)**2)/len(y)\n",
    "\n",
    "class Perceptron:\n",
    "    \n",
    "    def __init__(self, n_iterations=500,loss=MSE, activation_function=sigmoid, learning_rate=0.01):\n",
    "        self.n_iterations=n_iterations\n",
    "        self.loss=loss()\n",
    "        self.activation_function=activation_function()\n",
    "        self.learning_rate=learning_rate\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        n_samples, n_features=X.shape\n",
    "        # we randomly initialize the weights\n",
    "        W=np.random.rand(X.shape[1], y.shape[1])\n",
    "        for i in range(self.n_iterations):\n",
    "            # feed-forward <==> calcul of linear output of the Perceptron\n",
    "            y_hat=self.activation_function(X.dot(W))\n",
    "            # backpropagation (we apply here chain-formula)\n",
    "            gradient_loss_resp_w=X.T@self.loss.gradient(y,yp)*self.activation_function.gradient(X.dot(W))\n",
    "            # graient descent\n",
    "            w-=self.learning_rate*gradient_loss_resp_w\n",
    "            \n",
    "    def prediction(self, X):\n",
    "        return self.activation_function(X.dot(W))\n",
    "perceptron=Perceptron()\n",
    "perceptron.fit(x_train, y_train)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7d61b5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986013986013986\n",
      "0.7482517482517482\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test))\n",
    "from sklearn.linear_model import Perceptron  \n",
    "per=Perceptron()\n",
    "per.fit(x_train, y_train)\n",
    "per_pred=per.predict(x_test)\n",
    "print(accuracy_score(per_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "deb7a118",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_decision_regions' from 'matplotlib.pyplot' (/home/said/anaconda3/venv/lib/python3.10/site-packages/matplotlib/pyplot.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [57]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Perceptron\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m  \u001b[38;5;28;01mimport\u001b[39;00m plot_decision_regions\n\u001b[1;32m     10\u001b[0m iris \u001b[38;5;241m=\u001b[39m datasets\u001b[38;5;241m.\u001b[39mload_iris()\n\u001b[1;32m     11\u001b[0m X \u001b[38;5;241m=\u001b[39m iris\u001b[38;5;241m.\u001b[39mdata[:, [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]]\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'plot_decision_regions' from 'matplotlib.pyplot' (/home/said/anaconda3/venv/lib/python3.10/site-packages/matplotlib/pyplot.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.pyplot  import plot_decision_regions\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Feature scaling - computes mean and standard deviation\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n",
    "# Feed perceptron\n",
    "ppn = Perceptron(n_iter=40, eta0=0.1, random_state=0)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Missclassified samples: %d' % (y_test != y_pred).sum())\n",
    "print('Accuracy: %.2f' % accuracy_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))\n",
    "\n",
    "print (len(X_test.shape))\n",
    "plot_decision_regions(\n",
    "    X_combined_std,\n",
    "    y_combined,\n",
    "    clf=ppn,\n",
    "    res=0.02,\n",
    "    legend=2,\n",
    "    X_highlight=X_test\n",
    ")\n",
    "\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d75c242e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986013986013986\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "00d53088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=np.array(([i for i in range(10)]))\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b82d68a",
   "metadata": {},
   "source": [
    "# 2 MNIST-Neural Networks:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2818bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Networks:\n",
    "    \n",
    "    def __init__(self, layers=[784, 128, 64, 10], epochs=100, \n",
    "                      learning_rate=0.001, error_function=mean_squared_error, regularization=False):\n",
    "        pass\n",
    "    def forward(self):\n",
    "        pass\n",
    "    \n",
    "    def backward(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x_tarin, y_train):\n",
    "        pass\n",
    "    \n",
    "    def pred(self, x_test):\n",
    "        pass\n",
    "    \n",
    "    def show(self, precdict, plotting_accuracy, plotting_error_function):\n",
    "        ''' show the images on forme the int 1, 2,...etc '''\n",
    "        pass\n",
    "    \n",
    "    def Accuracy_Score(self):\n",
    "        pass\n",
    "    \n",
    "    def tuning_parameters(self, lr, epochs):\n",
    "        pass\n",
    "    \n",
    "    def regularization(self, para_reg):\n",
    "        pass\n",
    "    \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b571da3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
